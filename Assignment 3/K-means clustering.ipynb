{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "801c90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d63b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(file_path):\n",
    "    \"\"\"\n",
    "    Load MNIST images from the IDX file format.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: str, path to the idx3-ubyte file\n",
    "    \n",
    "    Returns:\n",
    "    - images: numpy.ndarray, shape (num_images, 28*28)\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        # Read the magic number and dimensions\n",
    "        magic, num_images, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError(f'Invalid magic number {magic} in image file: {file_path}')\n",
    "        \n",
    "        # Read the image data\n",
    "        image_data = f.read()\n",
    "        images = np.frombuffer(image_data, dtype=np.uint8)\n",
    "        images = images.reshape(num_images, rows * cols)\n",
    "        return images\n",
    "\n",
    "def load_labels(file_path):\n",
    "    \"\"\"\n",
    "    Load MNIST labels from the IDX file format.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: str, path to the idx1-ubyte file\n",
    "    \n",
    "    Returns:\n",
    "    - labels: numpy.ndarray, shape (num_labels,)\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        # Read the magic number and number of labels\n",
    "        magic, num_labels = struct.unpack('>II', f.read(8))\n",
    "        if magic != 2049:\n",
    "            raise ValueError(f'Invalid magic number {magic} in label file: {file_path}')\n",
    "        \n",
    "        # Read the label data\n",
    "        label_data = f.read()\n",
    "        labels = np.frombuffer(label_data, dtype=np.uint8)\n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6b3a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your MNIST files\n",
    "train_images_path = 'data/train-images.idx3-ubyte'\n",
    "train_labels_path = 'data/train-labels.idx1-ubyte'\n",
    "test_images_path = 'data/t10k-images.idx3-ubyte'\n",
    "test_labels_path = 'data/t10k-labels.idx1-ubyte'\n",
    "\n",
    "# Load the data\n",
    "X_train = load_images(train_images_path)\n",
    "y_train = load_labels(train_labels_path)\n",
    "X_test = load_images(test_images_path)\n",
    "y_test = load_labels(test_labels_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26b31944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train.astype(np.float64) / 255.0\n",
    "X_test = X_test.astype(np.float64) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34b9b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce dimensionality to 20\n",
    "pca = PCA(n_components=20, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e384fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_centroids(X, k):\n",
    "    #Randomly initialize centroids from the dataset X.\n",
    "    idx = np.random.choice(X.shape[0], k, replace=False)\n",
    "    return X[idx]\n",
    "\n",
    "def compute_distances(X, centroids):\n",
    "    #Compute the Euclidean distance between each data point in X and each centroid.\n",
    "    distances = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "    return distances\n",
    "\n",
    "def assign_clusters(distances):\n",
    "    #Assign each data point to the closest centroid.\n",
    "    return np.argmin(distances, axis=0)\n",
    "\n",
    "def update_centroids(X, labels, k):\n",
    "    #Compute the new centroids as the mean of the assigned data points.\n",
    "    centroids = np.array([X[labels == i].mean(axis=0) if len(X[labels == i]) > 0 else X[np.random.choice(X.shape[0])]for i in range(k)])\n",
    "    return centroids\n",
    "\n",
    "def k_means(X, k, max_iters=150, tol=1e-5):\n",
    "    #Perform k-means clustering.\n",
    "    centroids = initialize_centroids(X, k)\n",
    "    for i in range(max_iters):\n",
    "        old_centroids = centroids.copy()\n",
    "        distances = compute_distances(X, centroids)\n",
    "        labels = assign_clusters(distances)\n",
    "        centroids = update_centroids(X, labels, k)\n",
    "        # Check for convergence\n",
    "        centroid_shift = np.linalg.norm(centroids - old_centroids)\n",
    "        if centroid_shift < tol:\n",
    "            print(f\"Converged after {i+1} iterations for k={k}.\")\n",
    "            break\n",
    "    return labels, centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3374e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cluster_consistency(labels, true_labels, k):\n",
    "    cluster_consistencies = []\n",
    "    for cluster_id in range(k):\n",
    "        cluster_indices = np.where(labels == cluster_id)[0]\n",
    "        cluster_size = len(cluster_indices)\n",
    "        if cluster_size == 0:\n",
    "            Q_i = 0\n",
    "            print(f\"Cluster {cluster_id}: Empty cluster.\")\n",
    "        else:\n",
    "            # Count the occurrences of each true label in the cluster\n",
    "            counts = np.bincount(true_labels[cluster_indices], minlength=10)\n",
    "            m_i = np.max(counts)\n",
    "            Q_i = m_i / cluster_size\n",
    "            print(f\"Cluster {cluster_id}: N_i={cluster_size}, m_i={m_i}, Q_i={Q_i:.4f}\")\n",
    "        cluster_consistencies.append(Q_i)\n",
    "    return cluster_consistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "904520b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_clusters_to_test(X_test_pca, centroids):\n",
    "    \n",
    "    #Assign cluster labels to test data based on trained centroids.\n",
    "    \n",
    "    distances = compute_distances(X_test_pca, centroids)\n",
    "    test_labels = assign_clusters(distances)\n",
    "    return test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed27823a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running k-means with k=5\n",
      "Converged after 42 iterations for k=5.\n",
      "Calculating cluster consistency for k=5:\n",
      "Cluster 0: N_i=10880, m_i=5065, Q_i=0.4655\n",
      "Cluster 1: N_i=12493, m_i=5017, Q_i=0.4016\n",
      "Cluster 2: N_i=13975, m_i=6682, Q_i=0.4781\n",
      "Cluster 3: N_i=17251, m_i=5380, Q_i=0.3119\n",
      "Cluster 4: N_i=5401, m_i=4960, Q_i=0.9183\n",
      "Average cluster consistency for k=5: 0.5151\n",
      "\n",
      "Running k-means with k=10\n",
      "Converged after 39 iterations for k=10.\n",
      "Calculating cluster consistency for k=10:\n",
      "Cluster 0: N_i=8803, m_i=3692, Q_i=0.4194\n",
      "Cluster 1: N_i=5693, m_i=4826, Q_i=0.8477\n",
      "Cluster 2: N_i=8943, m_i=3172, Q_i=0.3547\n",
      "Cluster 3: N_i=3188, m_i=2474, Q_i=0.7760\n",
      "Cluster 4: N_i=6339, m_i=3688, Q_i=0.5818\n",
      "Cluster 5: N_i=5498, m_i=3010, Q_i=0.5475\n",
      "Cluster 6: N_i=6357, m_i=3409, Q_i=0.5363\n",
      "Cluster 7: N_i=7327, m_i=3901, Q_i=0.5324\n",
      "Cluster 8: N_i=3133, m_i=2843, Q_i=0.9074\n",
      "Cluster 9: N_i=4719, m_i=4150, Q_i=0.8794\n",
      "Average cluster consistency for k=10: 0.6383\n",
      "\n",
      "Running k-means with k=20\n",
      "Converged after 70 iterations for k=20.\n",
      "Calculating cluster consistency for k=20:\n",
      "Cluster 0: N_i=2538, m_i=2385, Q_i=0.9397\n",
      "Cluster 1: N_i=2711, m_i=2314, Q_i=0.8536\n",
      "Cluster 2: N_i=2507, m_i=2326, Q_i=0.9278\n",
      "Cluster 3: N_i=2750, m_i=2238, Q_i=0.8138\n",
      "Cluster 4: N_i=2695, m_i=1643, Q_i=0.6096\n",
      "Cluster 5: N_i=3594, m_i=1895, Q_i=0.5273\n",
      "Cluster 6: N_i=2536, m_i=2381, Q_i=0.9389\n",
      "Cluster 7: N_i=3260, m_i=2365, Q_i=0.7255\n",
      "Cluster 8: N_i=2698, m_i=2568, Q_i=0.9518\n",
      "Cluster 9: N_i=3731, m_i=1915, Q_i=0.5133\n",
      "Cluster 10: N_i=3386, m_i=2399, Q_i=0.7085\n",
      "Cluster 11: N_i=1994, m_i=1639, Q_i=0.8220\n",
      "Cluster 12: N_i=3140, m_i=2639, Q_i=0.8404\n",
      "Cluster 13: N_i=3230, m_i=2749, Q_i=0.8511\n",
      "Cluster 14: N_i=4209, m_i=2114, Q_i=0.5023\n",
      "Cluster 15: N_i=2689, m_i=2395, Q_i=0.8907\n",
      "Cluster 16: N_i=2414, m_i=2222, Q_i=0.9205\n",
      "Cluster 17: N_i=3062, m_i=1861, Q_i=0.6078\n",
      "Cluster 18: N_i=3746, m_i=702, Q_i=0.1874\n",
      "Cluster 19: N_i=3110, m_i=1694, Q_i=0.5447\n",
      "Average cluster consistency for k=20: 0.7338\n",
      "\n",
      "Running k-means with k=40\n",
      "Converged after 144 iterations for k=40.\n",
      "Calculating cluster consistency for k=40:\n",
      "Cluster 0: N_i=890, m_i=646, Q_i=0.7258\n",
      "Cluster 1: N_i=1344, m_i=1282, Q_i=0.9539\n",
      "Cluster 2: N_i=1513, m_i=1422, Q_i=0.9399\n",
      "Cluster 3: N_i=1115, m_i=954, Q_i=0.8556\n",
      "Cluster 4: N_i=1892, m_i=1286, Q_i=0.6797\n",
      "Cluster 5: N_i=1087, m_i=1001, Q_i=0.9209\n",
      "Cluster 6: N_i=1363, m_i=963, Q_i=0.7065\n",
      "Cluster 7: N_i=1792, m_i=1666, Q_i=0.9297\n",
      "Cluster 8: N_i=1324, m_i=1177, Q_i=0.8890\n",
      "Cluster 9: N_i=1369, m_i=1240, Q_i=0.9058\n",
      "Cluster 10: N_i=1095, m_i=1010, Q_i=0.9224\n",
      "Cluster 11: N_i=1440, m_i=1309, Q_i=0.9090\n",
      "Cluster 12: N_i=1182, m_i=1108, Q_i=0.9374\n",
      "Cluster 13: N_i=1090, m_i=479, Q_i=0.4394\n",
      "Cluster 14: N_i=1268, m_i=1104, Q_i=0.8707\n",
      "Cluster 15: N_i=1306, m_i=1006, Q_i=0.7703\n",
      "Cluster 16: N_i=1557, m_i=1328, Q_i=0.8529\n",
      "Cluster 17: N_i=1525, m_i=1468, Q_i=0.9626\n",
      "Cluster 18: N_i=1546, m_i=1242, Q_i=0.8034\n",
      "Cluster 19: N_i=1445, m_i=1356, Q_i=0.9384\n",
      "Cluster 20: N_i=1674, m_i=727, Q_i=0.4343\n",
      "Cluster 21: N_i=1479, m_i=1311, Q_i=0.8864\n",
      "Cluster 22: N_i=1726, m_i=745, Q_i=0.4316\n",
      "Cluster 23: N_i=1579, m_i=1181, Q_i=0.7479\n",
      "Cluster 24: N_i=2116, m_i=427, Q_i=0.2018\n",
      "Cluster 25: N_i=1529, m_i=1417, Q_i=0.9267\n",
      "Cluster 26: N_i=1425, m_i=1362, Q_i=0.9558\n",
      "Cluster 27: N_i=1459, m_i=1414, Q_i=0.9692\n",
      "Cluster 28: N_i=1882, m_i=1712, Q_i=0.9097\n",
      "Cluster 29: N_i=1526, m_i=1487, Q_i=0.9744\n",
      "Cluster 30: N_i=1754, m_i=1134, Q_i=0.6465\n",
      "Cluster 31: N_i=1151, m_i=1110, Q_i=0.9644\n",
      "Cluster 32: N_i=1997, m_i=1773, Q_i=0.8878\n",
      "Cluster 33: N_i=1399, m_i=776, Q_i=0.5547\n",
      "Cluster 34: N_i=1321, m_i=1159, Q_i=0.8774\n",
      "Cluster 35: N_i=2065, m_i=1001, Q_i=0.4847\n",
      "Cluster 36: N_i=1867, m_i=1691, Q_i=0.9057\n",
      "Cluster 37: N_i=1678, m_i=1577, Q_i=0.9398\n",
      "Cluster 38: N_i=2048, m_i=1065, Q_i=0.5200\n",
      "Cluster 39: N_i=1182, m_i=613, Q_i=0.5186\n",
      "Average cluster consistency for k=40: 0.7913\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the values of k\n",
    "k_values = [5, 10, 20, 40]\n",
    "\n",
    "consistency_results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\nRunning k-means with k={k}\")\n",
    "    labels, centroids = k_means(X_train_pca, k)\n",
    "    \n",
    "    # Compute cluster consistency\n",
    "    print(f\"Calculating cluster consistency for k={k}:\")\n",
    "    cluster_consistencies = compute_cluster_consistency(labels, y_train, k)\n",
    "    \n",
    "    # Report average cluster consistency\n",
    "    average_Q = np.mean(cluster_consistencies)\n",
    "    consistency_results[k] = average_Q\n",
    "    print(f\"Average cluster consistency for k={k}: {average_Q:.4f}\")\n",
    "    \n",
    "    # Assign clusters to test data based on training centroids\n",
    "    test_labels = assign_clusters_to_test(X_test_pca, centroids)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f5397bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster Consistency Results:\n",
      "k     Average Consistency Qi   \n",
      "5     0.5151                   \n",
      "10    0.6383                   \n",
      "20    0.7338                   \n",
      "40    0.7913                   \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCluster Consistency Results:\")\n",
    "print(f\"{'k':<5} {'Average Consistency Qi':<25}\")\n",
    "for k in k_values:\n",
    "    print(f\"{k:<5} {consistency_results[k]:<25.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70906f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
